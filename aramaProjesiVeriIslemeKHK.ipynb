{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bu yarışmada **Kanun Hükmünde Kararname** dosyaları için 91 belgenin incelendikten sonra bizden beklenilen görevler:\n",
        "\n",
        "- \"kategori\" alanının tespiti. Bu görevle ilgili olan [Mevcut Çalışmamız](https://github.com/iflGARAJI10100/taMAM/blob/main/aramaProjesiKategoriBulmaKHK%20(1).ipynb) için tıklayınız.\n",
        "- \"mukerrer_no\" alanının tespiti. Bu görevle ilgili olan [Mevcut Çalışmamız](https://github.com/iflGARAJI10100/taMAM/blob/main/aramaProjesiVeriIslemeMukerrerNoTespitModulu.ipynb) için tıklayınız.\n",
        "- \"madde_sayisi\" alanının tespiti. Bu görevle ilgili olan [Mevcut Çalışmamız](https://github.com/iflGARAJI10100/taMAM/blob/main/aramaProjesiMaddeSayisiBulmaMod%C3%BCl%C3%BC.ipynb) için tıklayınız.\n",
        "- \"rega_no, rega_tarihi, mevzuat_no ve mevzuat_tarihi\" alanlarının tespiti. Bu kodda ise bu alanalın tespitiyle alakalı çalışmalarımız mevcuttur."
      ],
      "metadata": {
        "id": "daTrOk3n_Gft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri işleme ve analizi için pandas kütüphanesi kullanılacaktır. Pandas kütüphanesi pd rumuzu ile kısaltılmıştır.\n",
        "\n",
        "Tarih verilerinin işlenmesi için **datetime** kütüphanesi kullanılacaktır."
      ],
      "metadata": {
        "id": "HB-XsYGW9qxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D4DSrSk9PiW8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verilerimiz Google Drive (bulut) üzerinde olduğu için Google Colab ile Google Drive arasında bağlantı kurulacaktır."
      ],
      "metadata": {
        "id": "Rvcw2Trh9vWF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8ZpPY4-Pmv1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive içinde Colab Notebooks klasörünün içinde TDDI2022 isimli klasörde verilerimizi sakladığımız için bu klasöre erişilecektir.\n",
        "\n",
        "***NOT:*** Bu klasörü daha önce oluşturmadıysanız %md TDDI2022 komutu veya Google Drive Ara Yüzü ile klasörü oluşturunuz!"
      ],
      "metadata": {
        "id": "jdpGmzE19777"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h47_PvbxT9QD"
      },
      "outputs": [],
      "source": [
        "%cd drive/\n",
        "%cd MyDrive/\n",
        "%cd Colab Notebooks/\n",
        "%cd TDDI2022/\n",
        "\n",
        "# Klasörün içeriğinin görülmesi için\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri İskeleti TDDI2022 klasöründe bulunan yarışma kapsamında yarışmacılara sağlanan **kanunum-nlp-doc-analysis-dataset.csv** dosyasının içindeki verileri pandas ile okuyarak oluşturulacaktır.\n",
        "\n",
        "Veri iskeleti oluşturulduktan sonra veri iskeleti ile ilgili bilgi ekrana yazdırılacaktır. Tam özetin yazdırılıp yazdırılmayacağı durumunu *verbose=True* (yazdırılsın) parametresi ile kontrol edilecektir. "
      ],
      "metadata": {
        "id": "UjDm7Y5d-Bcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMriHlEGPqbV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('kanunum-nlp-doc-analysis-dataset.csv')\n",
        "df.info(verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Veri İskeletinde **kategori** sütununun / alanının kaç gruptan ve bu grupların kaç satırdan / kayıttan oluştuğu ekrana yazdırılacaktır."
      ],
      "metadata": {
        "id": "VGCt_uU9-rPh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzFXWPNMX6Sb"
      },
      "outputs": [],
      "source": [
        "print(df.groupby('kategori').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verilerde yapacağımız ön çalışmada bizden istenilen değerleri araştıracağımız **Kanun Hükmünde Kararname** belgelerinin özelliklerini inceliyoruz."
      ],
      "metadata": {
        "id": "FyC2Hhhn-wfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHs_4PciDhp1"
      },
      "outputs": [],
      "source": [
        "print(df.loc[df['kategori'] == 'Kanun Hükmünde Kararname'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verilerde yaptığımız ek çalışmalarda ise veri kümesinin data_text sütunundaki / alanındaki içerik iki parçaya ayrılabileceği görülmüştür. Böylelikle data_text sütunu / alanı işlenirken belgeye ait bilgiler birinci parçada belgenin içeriği ikinci parçada görülebilir. Tüm data_text kayıtlarında yer alan ortak bir noktanın varlığını kontrol etmek için aşağıdaki kod yardımı ile \"Resmi belgelerin hepsinde 'Madde 1' verisi var mı?\" önermesini kontrol ediyoruz."
      ],
      "metadata": {
        "id": "NXb2hibHAzoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQh4ili67Og"
      },
      "outputs": [],
      "source": [
        "kayitSayisi = 91",
        "say = 0\n",
        "satirToplami, sutunToplami = df.shape\n",
        "for satir in range(satirToplami):\n",
        "  if df['data_text'][satir].find('Madde 1 -') != -1 and df['kategori'][satir] == 'Kanun Hükmünde Kararname':\n",
        "    say+=1\n",
        "if say==kayitSayisi:\n",
        "  print(say,'=',kayitSayisi,'yani data_text alanındaki toplam KHK belgesi sayısı ve her bir kayıtta \"Madde 1\" verisini içeren KHK belgelerinin sayısı birbirine eşittir.')\n",
        "else:\n",
        "  print('Tüm KHK belgelerinde aranan veri bulunamamıştır.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarıdaki bulguların önermemizi kanıtlaması doğrultusunda örnek bir kaydı ikiye bölerek **belge ile ilgili verileri toplayabileceğimiz baş kısmı** görelim. Yine bu baş kısmın **bizden istenilen değerlerler** ile ilgili bilgi içerip içermediğini görmek için dosyada mevcut olan veriyi de ekrana yazdıralım."
      ],
      "metadata": {
        "id": "Gk1HhSseBwui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "satir = 826\n",
        "print('\\nKategori: ',df['kategori'][satir],'\\n','Resmi Gazete No: ',df['rega_no'][satir],'\\n','Resmi Gazete Tarihi: ',df['rega_tarihi'][satir],'\\n','Mevzuat No: ',df['mevzuat_no'][satir],'\\n','Mevzuat Tarihi: ',df['mevzuat_tarihi'][satir],'\\n',35*'-','\\nİçerik:\\n',df['data_text'][satir][:df['data_text'][satir].find('Madde 1')],sep='')"
      ],
      "metadata": {
        "id": "BLbmpanbCDXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Örnek belgede de gözüktüğü üzere **aradığımız değerler** dosyanın ilk parçasında mevcuttur.\n",
        "\n",
        "**Kanun Hükmünde Kararname** kategorili toplam 91 belge mevcuttur. Belgelerden istenilen verilerin alınmasıyla ilgili takımımız 2 farklı yol bulmuştur.\n",
        "\n",
        "1. TDDİ **\"Question-Answering\"** NLP görevi kullanılarak değerlerin eldesi.\n",
        "2. Belgelerde bulunan ortak yazım kurallarını tespit ederek ve **Kural Bazlı Arama** yaparak değerlerin eldesi.\n",
        "\n",
        "Kodun devamında **iki yöntem** de gösterilecek, **artı ve eksileri** hakkında tartışılacak ve yöntemlerin **başarı oranları** verilecektir."
      ],
      "metadata": {
        "id": "JjmWmRgtC9oH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Yöntem | TDDİ Kullanılarak Verilerin Eldesi**"
      ],
      "metadata": {
        "id": "5esJANz6EGZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TDDİ kullanmak için öncelikle **transformers** mödülü yüklenilecektir. Modül [Gereksinimler.txt](https://github.com/iflGARAJI10100/taMAM/blob/main/Gereksinimler.txt) de de belirtildiği gibi **4.20.1** sürümünde yüklenecektir."
      ],
      "metadata": {
        "id": "XaCA-DsCmv9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgEu0Pj6Htp7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.20.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"Question-Answering\"** NLP görevini kullanırken ihtiyacımız olan **en işlevsel** modeli bulmak için [Hugging Face](https://huggingface.co/models?language=tr&pipeline_tag=question-answering&sort=downloads) sitesinden uygun modelleri araştırıyoruz.\n",
        "\n",
        "Daha sonra sırasıyla bu modellere **örnek bir belge** verip o belgeden bize verdiği değerleri asıl değerler ile **karşılaştıracak**, **doğruluk oranı** en yüksek olan modeli de projemizde kullanacağız.\n",
        "\n"
      ],
      "metadata": {
        "id": "SJ4QWtDinX-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRLjWAuHLahS"
      },
      "outputs": [],
      "source": [
        "# Modelleri kullanırken ihityacımız olan fonksiyonları çağrımakla başlıyoruz.\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "\n",
        "# Test edeceğimiz modellerin listesi\n",
        "modeller = [\"lserinol/bert-turkish-question-answering\",\"savasy/bert-base-turkish-squad\",\"yunusemreemik/logo-qna-model\",\"emre/distilbert-tr-q-a\",\"oguzhanolm/loodos-bert-base-uncased-QA-fine-tuned\"]\n",
        "\n",
        "for x in modeller:\n",
        "  # İçerik olarak önceki bulgularımıza dayanarak belgenin ilk kısmını seçiyoruz.\n",
        "  icerik = df['data_text'][satir][:df['data_text'][satir].find('Madde 1')]\n",
        "  \n",
        "  # TDDİ yaparken kullanacağımız soruların listesini ve cevapları tanımlıyoruz.\n",
        "  sorular = [\"Resmi Gazete Tarihi nedir?\",\"Resmi Gazete Sayısı nedir?\",\"Karar Sayısı Nedir?\",\"Kararnamenin Tarihi nedir?\"]\n",
        "  cevaplar = []\n",
        "\n",
        "  # Model hazırlanır.\n",
        "  veriBulucu = pipeline(task='question-answering', model=AutoModelForQuestionAnswering.from_pretrained(x), tokenizer=AutoTokenizer.from_pretrained(x))\n",
        "  \n",
        "  # Model adı verildikten sonra modelin sorulara verdiği cevaplar yazdırılır.\n",
        "  print(\"Model:\",x)\n",
        "  for soru in sorular:\n",
        "      sonuc = veriBulucu(question = soru, context = icerik)\n",
        "      cevaplar.append(sonuc['answer'])\n",
        "      print(\"'\",soru,\"'\",\"sorusuna verilen cevap:\",sonuc['answer'])\n",
        "  print(35*'-')\n",
        "\n",
        "# Karşılaştırma için asıl değerler yazdırılır.\n",
        "print('Kategori: ',df['kategori'][satir],'\\n','Resmi Gazete No: ',df['rega_no'][satir],'\\n','Resmi Gazete Tarihi: ',df['rega_tarihi'][satir],'\\n','Mevzuat No: ',df['mevzuat_no'][satir],'\\n','Mevzuat Tarihi: ',df['mevzuat_tarihi'][satir],'\\n',35*'-',sep='')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ÇIKARIM:***\n",
        "\n",
        "- **(ÖNEMLİ BULGU)** Basitçe Test ettiğimiz 5 modelden sadece 2' si istenilen performansı göstermiştir. Bu iki model de ileride daha detaylı test edilip yeniden en iyi performans göstereni seçilecektir.\n",
        "  - lserinol/bert-turkish-question-answering\n",
        "  - savasy/bert-base-turkish-squad \n",
        "\n",
        "Bu şekilde modellerin karşılaştırılması bittikten sonra **aranılan değerleri** bütün belgelerde aramaya veya iki modelimizn doğruluk oranlarını hesaplamaya geçebiliriz.\n"
      ],
      "metadata": {
        "id": "y8hg33Y7KO9T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKZlautbfMIE"
      },
      "outputs": [],
      "source": [
        "# Modelleri kullanırken ihityacımız olan fonksiyonları çağrımakla başlıyoruz.\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "\n",
        "# Performans ölçümünde kullanılacak değişkenlerin listelerin oluşturulması.\n",
        "degerlerimiz = [\"rega_tarihi\",\"rega_no\",\"mevzuat_no\",\"mevzuat_tarihi\"]\n",
        "belgelerdekiToplamDegerSayisi = 91\n",
        "belgelerdekiHataliDegerSayisi = [0] * len(degerlerimiz)\n",
        "\n",
        "# Test edeceğimiz modellerin listesi\n",
        "modeller = [\"lserinol/bert-turkish-question-answering\",\"savasy/bert-base-turkish-squad\"]\n",
        "\n",
        "# istenilen değerileri almamızı sağlayacak soruların listesi ve cevaplar listesi oluşturulur.\n",
        "sorular = [\"Resmi Gazete Tarihi nedir?\",\"Resmi Gazete Sayısı nedir?\",\"Karar Sayısı Nedir?\",\"Kararnamenin Tarihi nedir?\"]\n",
        "cevaplar = []\n",
        "\n",
        "for x in modeller:\n",
        "  # Performans Ölçümleri Sıfırlanır\n",
        "  degerlerimiz = [\"rega_no\",\"rega_tarihi\",\"mevzuat_no\",\"mevzuat_tarihi\"]\n",
        "  belgelerdekiToplamDegerSayisi = 91\n",
        "  belgelerdekiHataliDegerSayisi = [0] * len(degerlerimiz)\n",
        "\n",
        "  for satir in range(826,917):\n",
        "    # İçerik olarak önceki bulgularımıza dayanarak belgenin ilk kısmını seçiyoruz.\n",
        "    icerik = df['data_text'][satir][:df['data_text'][satir].find('Madde 1')]\n",
        "  \n",
        "    # Cevaplar listesi sıfırlanır.\n",
        "    cevaplar = []\n",
        "\n",
        "    # Model hazırlanır.\n",
        "    veriBulucu = pipeline(task='question-answering', model=AutoModelForQuestionAnswering.from_pretrained(x), tokenizer=AutoTokenizer.from_pretrained(x))\n",
        "\n",
        "    # Geçerli modelden değerler alınır.\n",
        "    for soru in sorular:\n",
        "      sonuc = veriBulucu(question = soru, context = icerik)\n",
        "      cevaplar.append(sonuc['answer'])\n",
        "\n",
        "    # Çekilen Değerlerin formatlanması.\n",
        "    if cevaplar[0].find(\"\\n\") != -1:\n",
        "      cevaplar[0] = cevaplar[0][:cevaplar[0].find(\"\\n\")]\n",
        "\n",
        "    if cevaplar[0].find(\"-\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d-%m-%Y\")\n",
        "    elif cevaplar[0].find(\".\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d.%m.%Y\")\n",
        "    elif cevaplar[0].find(\"/\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d/%m/%Y\")\n",
        "\n",
        "    regaNo = cevaplar[1]\n",
        "\n",
        "    mevzuatNo = cevaplar[2][cevaplar[2].find('/')+1:]\n",
        "    if cevaplar[3].find(\"\\n\") != -1:\n",
        "      cevaplar[3] = cevaplar[3][:cevaplar[3].find(\"\\n\")]\n",
        "\n",
        "    if cevaplar[3].find(\"-\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d-%m-%Y\")\n",
        "    elif cevaplar[3].find(\".\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d.%m.%Y\")\n",
        "    elif cevaplar[3].find(\"/\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d/%m/%Y\")\n",
        "\n",
        "    # Asıl Değerlerin formatlanması.\n",
        "    dfregaTarihi = datetime.strptime(df[\"rega_tarihi\"][satir],\"%Y-%m-%d\")\n",
        "    dfregaNo = df[\"rega_no\"][satir]\n",
        "    dfmevzuatTarihi = datetime.strptime(df[\"mevzuat_tarihi\"][satir],\"%Y-%m-%d\")\n",
        "    dfmevzuatNo = df[\"mevzuat_no\"][satir]\n",
        "\n",
        "    # Değerlerin Asılları ile Karşılaştırılması\n",
        "    if regaTarihi != dfregaTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[0]+=1\n",
        "\n",
        "    if regaNo != dfregaNo:\n",
        "      belgelerdekiHataliDegerSayisi[1]+=1\n",
        "      \n",
        "    if mevzuatNo != dfmevzuatNo:\n",
        "      belgelerdekiHataliDegerSayisi[2]+=1\n",
        "\n",
        "    if mevzuatTarihi != dfmevzuatTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[3]+=1\n",
        "\n",
        "  # Ölçüm bittiğinde Model ve Performansı Yazdırılır (İşlem Toplam 10dk civarı sürer)    \n",
        "  print(\"\\nModel: \",x) \n",
        "  for i in range(4):\n",
        "    print(degerlerimiz[i],\"|\",belgelerdekiHataliDegerSayisi[i],\"/\",belgelerdekiToplamDegerSayisi,\"|\",round((belgelerdekiToplamDegerSayisi-belgelerdekiHataliDegerSayisi[i])/belgelerdekiToplamDegerSayisi,3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ÇIKARIM:***\n",
        "\n",
        "- **(ÖNEMLİ BULGU)** 2 Modelden Daha Yüksek Performans gösteren Model **savasy/bert-base-turkish-squad** olmuştur. Bu yüzden bundan sonraki kodlarda model olarak o kullanılacaktır.\n",
        "\n",
        "- **(ÖNEMLİ BULGU)** **savasy/bert-base-turkish-squad** modeli **\"mevzuat_tarihi\"**\n",
        "değeri hariç diğer tüm değerlerde **Hatasız** çalışmaktadır.\n",
        "\n",
        "- **savasy/bert-base-turkish-squad** modeli **\"mevzuat_tarihi\"**\n",
        "değerinde  **Hatalı** çalışmaktadır.\n",
        "\n",
        "Görüldüğü üzere modelin performansını **Hatasız** hale getimek için **\"mevzuat_tarihi\"** değerinde çalışmalar yapılmalıdır."
      ],
      "metadata": {
        "id": "EB-z-nB1j5PM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeller'in Performans Tabloları\n",
        "**1. lserinol/bert-turkish-question-answering**\n",
        "\n",
        "|lserinol/bert-turkish-question-answering|Toplam|Doğru|Yanlış|Doğruluk Oranı|\n",
        "|---|---|---|---|---|\n",
        "|rega_tarihi|91|87|4|0.956|\n",
        "|rega_no|91|91|0|1.0|\n",
        "|mevzuat_tarihi|91|51|40|0.56|\n",
        "|mevzuat_no|91|91|0|1.0|\n",
        "\n",
        "**2. savasy/bert-base-turkish-squad**\n",
        "\n",
        "|savasy/bert-base-turkish-squad|Toplam|Doğru|Yanlış|Doğruluk Oranı|\n",
        "|---|---|---|---|---|\n",
        "|rega_tarihi|91|91|0|1.0|\n",
        "|rega_no|91|91|0|1.0|\n",
        "|mevzuat_tarihi|91|70|21|0.769|\n",
        "|mevzuat_no|91|91|0|1.0|"
      ],
      "metadata": {
        "id": "1aYWKPhJlxNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi **savasy/bert-base-turkish-squad** modelinin neden **mevzuat_tarihi** değerinde bu kadar hata verdiğine bakacağız. Hipotezlerimizden biri modelin onu o satırın **rega_tarihi** tahminiyle karıştırmasıdır. Şimdi bunu ölçmeyi deneyeceğiz."
      ],
      "metadata": {
        "id": "BaObFH9FoRNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelleri kullanırken ihityacımız olan fonksiyonları çağrımakla başlıyoruz.\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "\n",
        "# Performans ölçümünde kullanılacak değişkenlerin listelerin oluşturulması.\n",
        "degerlerimiz = [\"rega_tarihi\",\"rega_no\",\"mevzuat_no\",\"mevzuat_tarihi\"]\n",
        "belgelerdekiToplamDegerSayisi = 91\n",
        "belgelerdekiHataliDegerSayisi = [0] * len(degerlerimiz)\n",
        "\n",
        "# Test edeceğimiz modellerin listesi\n",
        "modeller = [\"savasy/bert-base-turkish-squad\"]\n",
        "\n",
        "# istenilen değerileri almamızı sağlayacak soruların listesi ve cevaplar listesi oluşturulur.\n",
        "sorular = [\"Resmi Gazete Tarihi nedir?\",\"Resmi Gazete Sayısı nedir?\",\"Karar Sayısı Nedir?\",\"Kararnamenin Tarihi nedir?\"]\n",
        "cevaplar = []\n",
        "\n",
        "for x in modeller:\n",
        "  # Performans Ölçümleri Sıfırlanır\n",
        "  degerlerimiz = [\"rega_no\",\"rega_tarihi\",\"mevzuat_no\",\"mevzuat_tarihi\"]\n",
        "  belgelerdekiToplamDegerSayisi = 91\n",
        "  belgelerdekiHataliDegerSayisi = [0] * len(degerlerimiz)\n",
        "  ayniTarih = 0\n",
        "\n",
        "  for satir in range(826,917):\n",
        "    # İçerik olarak önceki bulgularımıza dayanarak belgenin ilk kısmını seçiyoruz.\n",
        "    icerik = df['data_text'][satir][:df['data_text'][satir].find('Madde 1')]\n",
        "  \n",
        "    # Cevaplar listesi sıfırlanır.\n",
        "    cevaplar = []\n",
        "\n",
        "    # Model hazırlanır.\n",
        "    veriBulucu = pipeline(task='question-answering', model=AutoModelForQuestionAnswering.from_pretrained(x), tokenizer=AutoTokenizer.from_pretrained(x))\n",
        "\n",
        "    # Geçerli modelden değerler alınır.\n",
        "    for soru in sorular:\n",
        "      sonuc = veriBulucu(question = soru, context = icerik)\n",
        "      cevaplar.append(sonuc['answer'])\n",
        "\n",
        "    # Çekilen Değerlerin formatlanması.\n",
        "    if cevaplar[0].find(\"\\n\") != -1:\n",
        "      cevaplar[0] = cevaplar[0][:cevaplar[0].find(\"\\n\")]\n",
        "\n",
        "    if cevaplar[0].find(\"-\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d-%m-%Y\")\n",
        "    elif cevaplar[0].find(\".\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d.%m.%Y\")\n",
        "    elif cevaplar[0].find(\"/\") != -1:\n",
        "      regaTarihi = datetime.strptime(cevaplar[0],\"%d/%m/%Y\")\n",
        "\n",
        "    regaNo = cevaplar[1]\n",
        "\n",
        "    mevzuatNo = cevaplar[2][cevaplar[2].find('/')+1:]\n",
        "\n",
        "    if cevaplar[3].find(\"\\n\") != -1:\n",
        "      cevaplar[3] = cevaplar[3][:cevaplar[3].find(\"\\n\")]\n",
        "\n",
        "    if cevaplar[3].find(\"-\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d-%m-%Y\")\n",
        "    elif cevaplar[3].find(\".\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d.%m.%Y\")\n",
        "    elif cevaplar[3].find(\"/\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(cevaplar[3],\"%d/%m/%Y\")\n",
        "\n",
        "    # Asıl Değerlerin formatlanması.\n",
        "    dfregaTarihi = datetime.strptime(df[\"rega_tarihi\"][satir],\"%Y-%m-%d\")\n",
        "    dfregaNo = df[\"rega_no\"][satir]\n",
        "    dfmevzuatTarihi = datetime.strptime(df[\"mevzuat_tarihi\"][satir],\"%Y-%m-%d\")\n",
        "    dfmevzuatNo = df[\"mevzuat_no\"][satir]\n",
        "\n",
        "    # Değerlerin Asılları ile Karşılaştırılması\n",
        "    if regaTarihi != dfregaTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[0]+=1\n",
        "\n",
        "    if regaNo != dfregaNo:\n",
        "      belgelerdekiHataliDegerSayisi[1]+=1\n",
        "\n",
        "    if mevzuatNo != dfmevzuatNo:\n",
        "      belgelerdekiHataliDegerSayisi[2]+=1\n",
        "\n",
        "    if mevzuatTarihi != dfmevzuatTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[3]+=1\n",
        "      # Hipotezimizin denenmesi\n",
        "      if mevzuatTarihi == regaTarihi:\n",
        "        ayniTarih +=1\n",
        "\n",
        "    \n",
        "\n",
        "  # Ölçüm bittiğinde Model ve Performansı Yazdırılır (Artık işlem süresi 4dk 40 sn'ye düşmüştür)    \n",
        "  print(\"Model: \",x) \n",
        "  for i in range(4):\n",
        "    print(degerlerimiz[i],\"|\",belgelerdekiHataliDegerSayisi[i],\"/\",belgelerdekiToplamDegerSayisi,\"|\",round((belgelerdekiToplamDegerSayisi-belgelerdekiHataliDegerSayisi[i])/belgelerdekiToplamDegerSayisi,3))\n",
        "  print(\"Aynı Tarih Hata:\",ayniTarih,\"/\",belgelerdekiHataliDegerSayisi[3])"
      ],
      "metadata": {
        "id": "djQVZ6Owoon2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ÇIKARIM:***\n",
        "\n",
        "- **(ÖNEMLİ BULGU)** Modelimiz 91 Belgeden **21**'inde  **\"mevzuat_tarihi\"**ni **\"rega_tarihi\"** değeriyle karıştırmaktadır. Bu sorun çözülürse modelin performansı istenilen seviyeye ulaştırılabilir.\n",
        "\n",
        "## **YÖNTEMİN ARTI VE EKSİLERİ**\n",
        "### Artıları:\n",
        "- TDDİ kullanılarak modülün daha önce karşılaşmadığı metinleri doğru işleme olasılığı arttırılıyor.\n",
        "\n",
        "### Eksileri:\n",
        "- Seçilen bir modelin başka belge tiplerinde aynı performansı sergileyeceği belirsiz.\n",
        "- Performans'ın arttırılma çalışmaları emek istiyor.\n",
        "- Kodların çalışma süreleri diğer alternatiflere göre fazla uzun sürüyor.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ikEzyLcYs7KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Yöntem | Kural Bazlı Sistem ile Verilerin Eldesi**"
      ],
      "metadata": {
        "id": "tcRIIZ71u9BR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu Yöntemde ise Belgeler arası **ortak yazım şekillerine** dikkat edilerek veriler elde edilir."
      ],
      "metadata": {
        "id": "wl5LmfV_w4EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performans ölçümü için gerekli olan değişkenlerin oluşturulması\n",
        "degerlerimiz = [\"rega_tarihi\",\"rega_no\",\"mevzuat_no\",\"mevzuat_tarihi\"]\n",
        "belgelerdekiToplamDegerSayisi = 91\n",
        "belgelerdekiHataliDegerSayisi = [0] * len(degerlerimiz)\n",
        "\n",
        "# Sadece KHK kategorisindeki belgelerde işlem yapıyoruz.\n",
        "for i in range(826,917):\n",
        "  # VERİ TEMİZLEME İŞLEMLERİ\n",
        "  metin = df['data_text'][i][:df['data_text'][i].find('Madde 1')].lower()\n",
        "  metin = metin.replace('  ','')\n",
        "\n",
        "\n",
        "  # 'rega_tarihi' değerini bulan kod\n",
        "  regaTarihiIndex = metin.find('resmî gazete tarihi:')\n",
        "  regaTarihiIndex = regaTarihiIndex + len('resmî gazete tarihi: ')\n",
        "  regaTarihi= metin[regaTarihiIndex:regaTarihiIndex+10]\n",
        "\n",
        "  \n",
        "  # 'rega_no' değerini bulan kod\n",
        "  regaNoIndex = metin.find('resmî gazete sayısı: ')\n",
        "  regaNoIndex = regaNoIndex + len('resmî gazete sayısı: ')\n",
        "  regaNo = ''\n",
        "  rakambuldu = 0\n",
        "  while metin[regaNoIndex].isdigit() or rakambuldu==0:\n",
        "    if metin[regaNoIndex] == ' ' or metin[regaNoIndex] == '\\n':\n",
        "      rakambuldu = 0\n",
        "    elif metin[regaNoIndex].isdigit():\n",
        "      rakambuldu = 1\n",
        "      regaNo = regaNo + metin[regaNoIndex]\n",
        "    regaNoIndex = regaNoIndex + 1\n",
        "  regaNo = int(regaNo)\n",
        "\n",
        "  \n",
        "  # 'mevzuat_no' değerini bulan kod\n",
        "  mevzuatNoIndex = metin.find('karar sayısı : ')\n",
        "  mevzuatNoIndex = mevzuatNoIndex + len('karar sayısı : ') + 4\n",
        "  mevzuatNo = ''\n",
        "  rakambuldu = 0\n",
        "  while metin[mevzuatNoIndex].isdigit() or rakambuldu==0:\n",
        "    if metin[mevzuatNoIndex] == ' ' or metin[mevzuatNoIndex] == '\\n':\n",
        "      rakambuldu = 0\n",
        "    elif metin[mevzuatNoIndex].isdigit():\n",
        "      rakambuldu = 1\n",
        "      mevzuatNo = mevzuatNo + metin[mevzuatNoIndex]\n",
        "    mevzuatNoIndex = mevzuatNoIndex + 1\n",
        "  mevzuatNo = int(mevzuatNo)\n",
        "  \n",
        "\n",
        "  # 'mevzuat_tarihi' değerini bulan kod\n",
        "  mevzuatTarihiIndex = metin.find('kararnamenin tarihi : ')\n",
        "  mevzuatTarihiIndex = mevzuatTarihiIndex + len('kararnamenin tarihi : ')\n",
        "  mevzuatTarihi = metin[mevzuatTarihiIndex:mevzuatTarihiIndex+10]\n",
        "\n",
        "  mevzuatTarihi = mevzuatTarihi.replace('\\n', '')\n",
        "  mevzuatTarihi = mevzuatTarihi.replace(' ', '')\n",
        "  \n",
        "\n",
        "  # Asıl değerlerin dosyadan çekilmesi\n",
        "  dfRegaTarihi = df.loc[df['kategori'] == 'Kanun Hükmünde Kararname','rega_tarihi'][i]\n",
        "  dfRegaNo = int(df.loc[df['kategori'] == 'Kanun Hükmünde Kararname','rega_no'][i])\n",
        "  dfMevzuatNo = int(df.loc[df['kategori'] =='Kanun Hükmünde Kararname','mevzuat_no'][i])\n",
        "  dfMevzuatTarihi = df.loc[df['kategori'] == 'Kanun Hükmünde Kararname','mevzuat_tarihi'][i]\n",
        "\n",
        "  # Asıl değerlerin formatlanması\n",
        "  dfRegaTarihi = datetime.strptime(dfRegaTarihi, '%Y-%m-%d')\n",
        "  dfMevzuatTarihi = datetime.strptime(dfMevzuatTarihi, '%Y-%m-%d')\n",
        "\n",
        "  # Çekilen Değerlerin formatlanması\n",
        "  if regaTarihi.find(\"\\n\") != -1:\n",
        "    regaTarihi = regaTarihi[:regaTarihi.find(\"\\n\")]\n",
        "\n",
        "    if regaTarihi.find(\"-\") != -1:\n",
        "      regaTarihi = datetime.strptime(regaTarihi,\"%d-%m-%Y\")\n",
        "    elif regaTarihi.find(\".\") != -1:\n",
        "      regaTarihi = datetime.strptime(regaTarihi,\"%d.%m.%Y\")\n",
        "    elif regaTarihi.find(\"/\") != -1:\n",
        "      regaTarihi = datetime.strptime(regaTarihi,\"%d/%m/%Y\")\n",
        "\n",
        "  if mevzuatTarihi.find(\"\\n\") != -1:\n",
        "    mevzuatTarihi = mevzuatTarihi[:mevzuatTarihi.find(\"\\n\")]\n",
        "\n",
        "    if mevzuatTarihi.find(\"-\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(mevzuatTarihi,\"%d-%m-%Y\")\n",
        "    elif mevzuatTarihi.find(\".\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(mevzuatTarihi,\"%d.%m.%Y\")\n",
        "    elif mevzuatTarihi.find(\"/\") != -1:\n",
        "      mevzuatTarihi = datetime.strptime(mevzuatTarihi,\"%d/%m/%Y\")\n",
        "\n",
        "  # Çekilen Değerlerin Asıllarıyla Karşılaştırılması\n",
        "\n",
        "  # Değerlerin Asılları ile Karşılaştırılması\n",
        "    if regaTarihi != dfregaTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[0]+=1\n",
        "\n",
        "    if regaNo != dfregaNo:\n",
        "      belgelerdekiHataliDegerSayisi[1]+=1\n",
        "\n",
        "    if mevzuatNo != dfmevzuatNo:\n",
        "      belgelerdekiHataliDegerSayisi[2]+=1\n",
        "\n",
        "    if mevzuatTarihi != dfmevzuatTarihi:\n",
        "      belgelerdekiHataliDegerSayisi[3]+=1\n",
        "\n",
        "# Kodun Performansının Yazdırılması\n",
        "for i in range(4):\n",
        "    print(degerlerimiz[i],\"|\",belgelerdekiHataliDegerSayisi[i],\"/\",belgelerdekiToplamDegerSayisi,\"|\",round((belgelerdekiToplamDegerSayisi-belgelerdekiHataliDegerSayisi[i])/belgelerdekiToplamDegerSayisi,3))\n",
        "  "
      ],
      "metadata": {
        "id": "Mq1r0jPzws85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ÇIKARIM:***\n",
        "\n",
        "- **(ÖNEMLİ BULGU)** Bu yöntemle modülümüz istenilen performans düzeyine ulaşmıştır. Bütün istenilen değerleri **Hatasız** şekilde bulabilmiştir.\n",
        "\n",
        "## **YÖNTEMİN ARTI VE EKSİLERİ**\n",
        "### Artıları:\n",
        "- Kural Bazlı Arama'sı diğer yöntemlere hız bakımından üstün.\n",
        "- Kural Bazlı Arama'sı 1.0 Doğruluk Performansıyla çalışıyor.\n",
        "\n",
        "### Eksileri:\n",
        "- Kural Bazlı Arama'nın diğer belge tiplerinde nasıl çalışacağı bilinmiyor.\n",
        "- Kural Bazlı Arama'nın yeni yazım kurallarına göre yazılmış metinlerde Doğruluk oranı 0.0'a kadar düşebilir, riskli."
      ],
      "metadata": {
        "id": "sKU6u7WN2hHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Yöntemin Performans Tablosu**\n",
        "\n",
        "|Kural Bazlı Arama Yöntemi|Toplam|Doğru|Yanlış|Doğruluk Oranı|\n",
        "|---|---|---|---|---|\n",
        "|rega_tarihi|91|91|0|1.0|\n",
        "|rega_no|91|91|0|1.0|\n",
        "|mevzuat_tarihi|91|91|0|1.0|\n",
        "|mevzuat_no|91|91|0|1.0|"
      ],
      "metadata": {
        "id": "w680Fomj20c8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "P1SS39NIj6A2",
        "QzVqg9uIlGIw",
        "XaCA-DsCmv9_",
        "1deSpvpPm-vL",
        "SJ4QWtDinX-F"
      ],
      "name": "aramaProjesiKHKdoldurma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
